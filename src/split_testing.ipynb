{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "Models are either capped at `1024` or `512` tokens. To summarize our notes, let's split each note into appropriate sections by reading in the headers. Each section will be summarized separately,and those strings will then be concatenated together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from functions import summarize, summarize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HEADER_DEPTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_note = \"/Users/joachimpfefferkorn/repos/daily_note_organizer/test_media/2023-10-17.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_md(md_content: str):\n",
    "    #TODO\n",
    "    # Remove hyperlinks\n",
    "    # Disregard edge cases, anything encapsulated in a code block\n",
    "    # use a look up table of strings to replace instead of this shadowed variable\n",
    "    clean_note = md_content\n",
    "    clean_note = clean_note.replace('- [x]', 'Completed:').replace('- [ ]','To Do:')\n",
    "    clean_note = clean_note.replace('[[', '').replace(']]','')\n",
    "    clean_note = clean_note.replace('![[', 'Image file:')\n",
    "    return clean_note\n",
    "\n",
    "def prepare_note(md_path):\n",
    "    with open(md_path, 'r') as note:\n",
    "        md_content = note.read()\n",
    "        cleaned_md = clean_md(md_content)\n",
    "        return cleaned_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_note = prepare_note(str(long_note))\n",
    "# print(type(prepared_note))\n",
    "#print(prepared_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': '\"Automate the Boring Stuff with Python\" by \"Al Sweigart\" is a book in which you will learn to code. I am new to Monty Python\\'s Language. I know a lot about coding, debugging and sharing my knowledge with others. My IQ was 143 when I was a teenager. I attended the United States Military Academy at West Point, NY. I worked as an engineer for 30 years coding IBM Assembler, PL/1, REXX, and various \"Print Scripting Languages,\" debugging, advising, co-operating with others, and writing internal help guides for my co-workers. I was designated a \"Principal Engineer,\" 1 of 2,000 IT employees, but left due to injury. '}]\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "bad_python = \"\"\"\"Automate the Boring Stuff with Python?\" by \"Al Sweigart\" sounds like a book in which you will learn\n",
    "to \"automate\" something?\" You do not! \"Automate the Boring Stuff with Python\" leaves me floundering with\n",
    "\"incomplete\" examples of code! Please, provide complete examples. Do not leave it to me to complete your\n",
    "partial examples. I am trying to LEARN the language now, not wander on the path of the unknown. I am new to\n",
    "Monty Python's Language! Guido van Rossum didn't create anything. He \"developed\" something!\n",
    "What he developed is incomplete, confusing and not well thought out! The language is dependent on\n",
    "\"Indentation!\" This is a poor choice! Comments are limited to \"#\" and do not encompass multiple lines\n",
    "of code like the \"C\" language family's comment structure of (/* ... */!) This is another of \"Al Sweigart's\"\n",
    "disappointing books! Python requires a paradigm shift that I am trying to make after 30 years of IBM Mainframe 360 familiy to today's\n",
    "\"System Z\" of coding IBM Assembler, PL/1, REXX, and various \"Print Scripting Languages,\" debugging, advising, co-operating with others\n",
    "in IT, and writing internal help guides for my co-workers! My last job I was designated a \"Principal Engineer,\" 1 of 2,000 IT\n",
    "employees. There were 20 of us at the time. I DO know something about coding, debugging and sharing my knowledge with others.\n",
    "I am not bragging! This is just a fact! I am disappointed with \"Automate the Boring Stuff with Python\" and do hope that \"Al Sweigart\"\n",
    "will write, or edit his books, to be complete for us \"beginners\" trying to slog along the path of learnig a \"Not\" supposedly \"Easy To\n",
    "Learn Programming Language\" that many major development companies use! I am not dumb. My IQ \"was\" quantified at 143 when I was a\n",
    "teenager. I did attended the United States Military Academy (USMA) at West Point, NY. for two years. I have an \"Honorable Discharge\"\n",
    "and left due to a torn ligament in the knee of my left leg. Year end PT did not go well! I ran for part of the course, and walked the\n",
    "remainder. My \"time\" at the end was below the required.\n",
    "West Point was hard to get into, and harder to stay. We carried 23 hour's of \"Not Easy\" course work per Semester!\n",
    "This included my choice of the\"Russian Language!,\" a well developed language, but difficult to learn! Looking back,\n",
    "I should have picked \"Spanish\" considering where my family chose to live in my waning years! I left the University\n",
    "I was attending as a Freshman, started over as a Plebe (4th Classman, Freshman,) at USMA, WP, NY., stayed 2 years,\n",
    "and returned to my original University and graduated with a BS in Math, Comp Sci., Life Sci., or, as the Degree was\n",
    "called, \"General Science.\" Please, \"Mr. Al Sweigart\" write books that are \"Complete\" for those beginneres, trying\n",
    "to learn a new programming language!\" I do Thank You \"Mr. Al Sweigart\" for you efforts! Please, write \"Complete\"\n",
    "books for the newbies sinking in the many programming languages coming and going today!\"\"\"\n",
    "\n",
    "print(summarize_string(bad_python, summarizer, tokenizer))\n",
    "print(type(bad_python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_split(note):\n",
    "    \"\"\"Dead Simple, MVP split, right down the middle of the note\"\"\"\n",
    "    #These leaves a lot to be desired, but test with this MVP for now\n",
    "    midpoint = int(len(note) / 2)\n",
    "    return [note[:midpoint]] + [note[midpoint:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joachimpfefferkorn/repos/daily_note_organizer/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"knkarthick/MEETING_SUMMARY\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n"
     ]
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "        self.tokens = tokenizer(content)\n",
    "        self.num_tokens = len(self.tokens['input_ids']) #TODO there is a direct way to get these, slight hack for now\n",
    "\n",
    "print(Section(prepared_note).num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split(section: Section, amount: int):\n",
    "    lines = np.asarray(section.content.split(\"\\n\"), dtype=str)\n",
    "\n",
    "    sub_arrays = np.array_split(lines, amount)\n",
    "\n",
    "    sections = []\n",
    "    #Make each sub array a string\n",
    "    for array in sub_arrays:\n",
    "        text = \"\\n\".join(array)\n",
    "    # then a section\n",
    "    #add each section to a list\n",
    "        sections.append(Section(text))\n",
    "    return sections\n",
    "\n",
    "# test_section = Section(prepared_note)\n",
    "# print(test_section.num_tokens)\n",
    "# splits = split(test_section, 4)\n",
    "# print(len(splits))\n",
    "# for i, section in enumerate(splits):\n",
    "#     print(f\"SECTION{i}:\\n\", section.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'section' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m split_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m sections \u001b[38;5;241m=\u001b[39m split(Section(prepared_note), split_amount)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mbiggest_section\u001b[49m\u001b[43m(\u001b[49m\u001b[43msections\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnum_tokens \u001b[38;5;241m>\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mmodel_max_length:\n\u001b[1;32m     12\u001b[0m     split_amount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     new_sections \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[240], line 3\u001b[0m, in \u001b[0;36mbiggest_section\u001b[0;34m(sections)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbiggest_section\u001b[39m(sections):\n\u001b[1;32m      2\u001b[0m     biggest_section \u001b[38;5;241m=\u001b[39m Section(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m \u001b[43msection\u001b[49m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mnum_tokens \u001b[38;5;241m>\u001b[39m biggest_section\u001b[38;5;241m.\u001b[39mnum_tokens:\n\u001b[1;32m      5\u001b[0m             biggest_section \u001b[38;5;241m=\u001b[39m section\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'section' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "def biggest_section(sections):\n",
    "    biggest_section = Section(\"\")\n",
    "    for section in section:\n",
    "        if section.num_tokens > biggest_section.num_tokens:\n",
    "            biggest_section = section\n",
    "    return biggest_section\n",
    "\n",
    "split_amount = 1\n",
    "sections = split(Section(prepared_note), split_amount)\n",
    "\n",
    "while biggest_section(sections).num_tokens > tokenizer.model_max_length:\n",
    "    split_amount += 1\n",
    "    new_sections = []\n",
    "    for section in sections:\n",
    "        if section.num_tokens > tokenizer.model_max_length:\n",
    "            new_sections.append(split(section, split_amount))\n",
    "        else:\n",
    "            new_sections.append(section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "    print(type(note))\n",
    "    print(len(tokenizer(note)[0]))\n",
    "    #print(summarize_string(note, summarizer, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
