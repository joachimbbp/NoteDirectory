{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "Models are either capped at `1024` or `512` tokens. To summarize our notes, let's split each note into appropriate sections by reading in the headers. Each section will be summarized separately,and those strings will then be concatenated together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from functions import summarize, summarize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HEADER_DEPTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_note = \"/Users/joachimpfefferkorn/repos/daily_note_organizer/test_media/2023-10-17.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_md(md_content: str):\n",
    "    #TODO\n",
    "    # Remove hyperlinks\n",
    "    # Disregard edge cases, anything encapsulated in a code block\n",
    "    # use a look up table of strings to replace instead of this shadowed variable\n",
    "    clean_note = md_content\n",
    "    clean_note = clean_note.replace('- [x]', 'Completed:').replace('- [ ]','To Do:')\n",
    "    clean_note = clean_note.replace('[[', '').replace(']]','')\n",
    "    clean_note = clean_note.replace('![[', 'Image file:')\n",
    "    return clean_note\n",
    "\n",
    "def prepare_note(md_path):\n",
    "    with open(md_path, 'r') as note:\n",
    "        md_content = note.read()\n",
    "        cleaned_md = clean_md(md_content)\n",
    "        return cleaned_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_note = prepare_note(str(long_note))\n",
    "# print(type(prepared_note))\n",
    "#print(prepared_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': '\"Automate the Boring Stuff with Python\" by \"Al Sweigart\" is a book in which you will learn to code. I am new to Monty Python\\'s Language. I know a lot about coding, debugging and sharing my knowledge with others. My IQ was 143 when I was a teenager. I attended the United States Military Academy at West Point, NY. I worked as an engineer for 30 years coding IBM Assembler, PL/1, REXX, and various \"Print Scripting Languages,\" debugging, advising, co-operating with others, and writing internal help guides for my co-workers. I was designated a \"Principal Engineer,\" 1 of 2,000 IT employees, but left due to injury. '}]\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "bad_python = \"\"\"\"Automate the Boring Stuff with Python?\" by \"Al Sweigart\" sounds like a book in which you will learn\n",
    "to \"automate\" something?\" You do not! \"Automate the Boring Stuff with Python\" leaves me floundering with\n",
    "\"incomplete\" examples of code! Please, provide complete examples. Do not leave it to me to complete your\n",
    "partial examples. I am trying to LEARN the language now, not wander on the path of the unknown. I am new to\n",
    "Monty Python's Language! Guido van Rossum didn't create anything. He \"developed\" something!\n",
    "What he developed is incomplete, confusing and not well thought out! The language is dependent on\n",
    "\"Indentation!\" This is a poor choice! Comments are limited to \"#\" and do not encompass multiple lines\n",
    "of code like the \"C\" language family's comment structure of (/* ... */!) This is another of \"Al Sweigart's\"\n",
    "disappointing books! Python requires a paradigm shift that I am trying to make after 30 years of IBM Mainframe 360 familiy to today's\n",
    "\"System Z\" of coding IBM Assembler, PL/1, REXX, and various \"Print Scripting Languages,\" debugging, advising, co-operating with others\n",
    "in IT, and writing internal help guides for my co-workers! My last job I was designated a \"Principal Engineer,\" 1 of 2,000 IT\n",
    "employees. There were 20 of us at the time. I DO know something about coding, debugging and sharing my knowledge with others.\n",
    "I am not bragging! This is just a fact! I am disappointed with \"Automate the Boring Stuff with Python\" and do hope that \"Al Sweigart\"\n",
    "will write, or edit his books, to be complete for us \"beginners\" trying to slog along the path of learnig a \"Not\" supposedly \"Easy To\n",
    "Learn Programming Language\" that many major development companies use! I am not dumb. My IQ \"was\" quantified at 143 when I was a\n",
    "teenager. I did attended the United States Military Academy (USMA) at West Point, NY. for two years. I have an \"Honorable Discharge\"\n",
    "and left due to a torn ligament in the knee of my left leg. Year end PT did not go well! I ran for part of the course, and walked the\n",
    "remainder. My \"time\" at the end was below the required.\n",
    "West Point was hard to get into, and harder to stay. We carried 23 hour's of \"Not Easy\" course work per Semester!\n",
    "This included my choice of the\"Russian Language!,\" a well developed language, but difficult to learn! Looking back,\n",
    "I should have picked \"Spanish\" considering where my family chose to live in my waning years! I left the University\n",
    "I was attending as a Freshman, started over as a Plebe (4th Classman, Freshman,) at USMA, WP, NY., stayed 2 years,\n",
    "and returned to my original University and graduated with a BS in Math, Comp Sci., Life Sci., or, as the Degree was\n",
    "called, \"General Science.\" Please, \"Mr. Al Sweigart\" write books that are \"Complete\" for those beginneres, trying\n",
    "to learn a new programming language!\" I do Thank You \"Mr. Al Sweigart\" for you efforts! Please, write \"Complete\"\n",
    "books for the newbies sinking in the many programming languages coming and going today!\"\"\"\n",
    "\n",
    "print(summarize_string(bad_python, summarizer, tokenizer))\n",
    "print(type(bad_python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_split(note):\n",
    "    \"\"\"Dead Simple, MVP split, right down the middle of the note\"\"\"\n",
    "    #These leaves a lot to be desired, but test with this MVP for now\n",
    "    midpoint = int(len(note) / 2)\n",
    "    return [note[:midpoint]] + [note[midpoint:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joachimpfefferkorn/repos/daily_note_organizer/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"knkarthick/MEETING_SUMMARY\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n"
     ]
    }
   ],
   "source": [
    "class Section:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "        self.tokens = tokenizer(content)\n",
    "        self.num_tokens = len(self.tokens['input_ids']) #TODO there is a direct way to get these, slight hack for now\n",
    "\n",
    "print(Section(prepared_note).num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split(section: Section, amount: int):\n",
    "    lines = np.asarray(section.content.split(\"\\n\"), dtype=str)\n",
    "\n",
    "    sub_arrays = np.array_split(lines, amount)\n",
    "\n",
    "    sections = []\n",
    "    #Make each sub array a string\n",
    "    for array in sub_arrays:\n",
    "        text = \"\\n\".join(array)\n",
    "    # then a section\n",
    "    #add each section to a list\n",
    "        sections.append(Section(text))\n",
    "    return sections\n",
    "\n",
    "# test_section = Section(prepared_note)\n",
    "# print(test_section.num_tokens)\n",
    "# splits = split(test_section, 30)\n",
    "# print(len(splits))\n",
    "# for i, section in enumerate(splits):\n",
    "#     print(f\"SECTION{i}:\\n\", section.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Section'>\n",
      "üêò Original section must be split by 2! Section tokens: 2718 Max model length: 1024\n",
      "ü™∏ New sections updated with split subsections, üîÉ recursively split is recursing\n",
      "‚öîÔ∏è Splitting subsection 0\n",
      "üêò Original section must be split by 3! Section tokens: 1394 Max model length: 1024\n",
      "ü™∏ New sections updated with split subsections, üîÉ recursively split is recursing\n",
      "‚öîÔ∏è Splitting subsection 0\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "‚öîÔ∏è Splitting subsection 1\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "‚öîÔ∏è Splitting subsection 2\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "‚öîÔ∏è Splitting subsection 1\n",
      "üêò Original section must be split by 3! Section tokens: 1325 Max model length: 1024\n",
      "ü™∏ New sections updated with split subsections, üîÉ recursively split is recursing\n",
      "‚öîÔ∏è Splitting subsection 0\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "‚öîÔ∏è Splitting subsection 1\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "‚öîÔ∏è Splitting subsection 2\n",
      "ü¶ã Section is small enough!\n",
      "üèÑ Small enough section added to new_sections\n",
      "[<__main__.Section object at 0x1462c7d90>, <__main__.Section object at 0x145774c10>, <__main__.Section object at 0x1462b3910>, <__main__.Section object at 0x14689ded0>, <__main__.Section object at 0x146adcc90>, <__main__.Section object at 0x147d6ced0>]\n"
     ]
    }
   ],
   "source": [
    "def biggest_section(sections):\n",
    "    biggest_section = Section(\"\")\n",
    "    for section in sections:\n",
    "        if section.num_tokens > biggest_section.num_tokens:\n",
    "            biggest_section = section\n",
    "    return biggest_section\n",
    "\n",
    "output_sections = []\n",
    "og_section = Section(prepared_note)\n",
    "def recursive_split(input_section, split_amount):\n",
    "\n",
    "    if input_section.num_tokens > tokenizer.model_max_length and split_amount < 99:\n",
    "        split_amount += 1\n",
    "        print(f\"üêò Original section must be split by {split_amount}! Section tokens: {input_section.num_tokens} Max model length: {tokenizer.model_max_length}\")\n",
    "        new_sections = split(og_section, split_amount)\n",
    "        print(f\"ü™∏ New sections updated with split subsections, üîÉ recursively split is recursing\")\n",
    "        for i, subsection in enumerate(new_sections):\n",
    "            print(f\"‚öîÔ∏è Splitting subsection {i}\")\n",
    "            recursive_split(subsection, split_amount)\n",
    "    else:\n",
    "        print(f\"ü¶ã Section is small enough!\")\n",
    "        print(f\"üèÑ Small enough section added to new_sections\")\n",
    "        output_sections.append(input_section)\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "split_amount = 1\n",
    "input_sections = split(Section(prepared_note), split_amount)\n",
    "print(type(input_sections[0]))\n",
    "# for section in sections:\n",
    "#     print(section.content)\n",
    "\n",
    "recursive_split(og_section, split_amount)\n",
    "print(output_sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION:  0 #dailyNote \n",
      "\n",
      "spam for note testing\n",
      "\n",
      "more preamble\n",
      "\n",
      "# Afternoon To-Do\n",
      "#meta #todoList \n",
      "## Priority\n",
      "Completed: Complete Python module\n",
      "Completed: Complete Bias and Variance\n",
      "## Bonus/tomorrow:\n",
      "Completed: Note cleanup with Aliases (see Career and Study To - Do)\n",
      "To Do: Linear Algebra Note Migration\n",
      "Completed: Integrate with this daily note\n",
      "\t\tTo Do: Training, Test, and Dev Sets\n",
      "\t\tTo Do: regularization (#merge and integrate)\n",
      "\t\tTo Do: Cost and Loss\n",
      "Completed: Big overhaul of Bias and Variance with regards to todays notes. \n",
      "# Machine Learning Specialization Notes:\n",
      "These notes will be integrated into other notes but kept here in their entirety.\n",
      "## Bias and Variance\n",
      "Machine Learning Specialization Advanced Machine Learning Algorithms, Week 3\n",
      "\n",
      "Models almost never work the first time you try them out. Let's see how we can fix them.\n",
      "\n",
      "### Diagnosing Bias/Variance\n",
      "See Bias and Variance\n",
      "\n",
      "If you have more features, you can't visualize Bias and Variance\n",
      "\n",
      "A more systematic way to see if you have high bias or high variance is to look at the performance of the algorithm on the Training, Test, and Dev Sets|training set and dev set\n",
      "\n",
      "A characteristic of a High Bias (under-fit) model is that $Jtrain$ (cost of the Training, Test, and Dev Sets|training set) is high.\n",
      "A characteristic of a High Variance (overfit) model is that $J_{cv}$ is high but $J_{train}$ is low.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.26.00 PM.png\n",
      "\n",
      "### Understanding Bias and Variance\n",
      "Take degree of polynomial $d$\n",
      "As $d$ increases, that is to say we add degrees to the polynomial\n",
      "$J_{train}({\\vec{w},b})$  will decrease.\n",
      "$J_{cv}(\\vec{w},b)$ dips towards the middle, showing the ideal degree for the polynomial.\n",
      "\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.29.21 PM.png\n",
      "\n",
      "### Technique for Diagnosing Bias and Variance\n",
      "How do you tell if your algorithm has a high bias or variance problem?\n",
      "\n",
      "One key takeaway is that high bias means it is not even doing well on the training set and high variance means it does much worse on the cross validation set and the training set.\n",
      "#### High Bias (under-fit)\n",
      "In an under-fit model $J_{train}$ will be high and $J_{train} \\approx J_{cv}$ \n",
      "#### High Variance (overfit)\n",
      "In an over-fit model $J_{cv} \\gg J_{train}$ and $J_{train}$ will be low.\n",
      "#### High Bias and High Variance\n",
      "In a model with both high bias and high variance $J_{train}$ will be high and $J_{cv} \\gg J_{train}$ \n",
      "This is rare, and doesn't really happen for linear models with one $d$, but it does happen.\n",
      "This is when it overfits for some part of the input and under-fits for another part of the input.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.38.51 PM.png\n",
      "\n",
      "## Regularization and bias/variance\n",
      "### Linear Regression with Regularization\n",
      "Regularized Linear Regression model:\n",
      "Lambda $\\lambda$ is the regularization parameter\n",
      "(Big #merge and cleanup needed here in the regularization, Regularized Linear Regression, cost, Cost and Loss, loss, Loss Function, etc. Aliases are needed in many of these)\n",
      "\n",
      "Take this model: $$f_{\\vec{w},b}(x)=w_1+w_2x^2 + w_4x^4+b$$\n",
      "SECTION:  1 With this regularization|regularized Cost and Loss $$J(\\vec{w},b)=\\frac{1}{2m} \\sum_{i=1}^{m}(f_{\\vec{w},{b}}(\\vec{x}^{(i)}-y^{(i)})^2+\\frac{\\lambda}{2m} \\sum_{j=1}^nw_j^2$$\n",
      "\n",
      "If lambda is large, say $\\lambda = 10,000$ than $w_1 \\approx 0, W_2 \\approx 0$ and $f_{\\vec{x},b}\\vec{x} \\approx b$, thus the model creates a flat line.\n",
      "This is underfit, $J_{train}()\n",
      "\n",
      "On the other hand, if we set $\\lambda=0$, then we have a forth order polynomial with no regularization. We end up with a very overfit curve.\n",
      "\n",
      "So, how do we find a good value for $\\lambda$?\n",
      "##### Slide\n",
      "!Screenshot 2023-10-17 at 3.56.53 PM.png\n",
      "### Choosing the Regularization parameter $\\lambda$ \n",
      "\n",
      "This will be similar to choosing $d$ with cross validation\n",
      "Try multiple values for $\\lambda$ and then choose the option with the lowest cost.\n",
      "### Slide\n",
      "!Screenshot 2023-10-17 at 4.15.27 PM.png\n",
      "### Bias and Variance as a Function of regularization parameter $\\lambda$ \n",
      "Cross Validation tries out many versions of $\\lambda$ and then chooses the one with the lowest cost.\n",
      "Cross validation will help find us a a good value of $d$ as well as $\\lambda$ \n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 4.14.07 PM.png\n",
      "\n",
      "\n",
      "## Establishing A Baseline Level of Performance\n",
      "### Speech Recognition example\n",
      "Job is to take in audio and output the text of what a person is saying\n",
      "\n",
      "Training error $J_{train}$ is percentage of audio clips that the program does not transcribe correctly in it's entirety.\n",
      "Lets say:\n",
      "\tHuman Level Performance: 10.6\n",
      "\t$J_{train}$: 10.8%\n",
      "\t$J_{cv}$: 14.8%\n",
      "\n",
      "Why is human level error so high? There is lots of noise in the audio. It seems unfair to expect a learning algorithm to do much better.\n",
      "It is thus is more useful to measure the training error against the human error.\n",
      "So, looking at these results, $J_{train}$ is only 0.2$ higher than the human level performance whereas $J_{cv}$ is a full 4.2% higher.\n",
      "We can thus conclude that this algorithm has more of a variance problem than a bias problem.\n",
      "### Establishing a baseline level of performance\n",
      "What is the level of error you can reasonably hope to get to?\n",
      "- Human level performance\n",
      "- Competing algorithms performance\n",
      "- Guess based on experience\n",
      "### Bias Variance Examples\n",
      "Gap between baseline and training error shows high bias.\n",
      "A gap between training error and cross validation error shows high variance.\n",
      "\n",
      "If your goal is perfection, the baseline would be zero. But for a lot of real world examples, like audio recognition, there is a lot of noise in the data, so you need a higher baseline.\n",
      "\n",
      "If there is a gap between all three is high you have both high bias and high variance.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 4.42.49 PM.png\n",
      "\n",
      "\n",
      "## Learning Curves\n",
      "\n",
      "Noted in Learning Curves\n",
      "### Overview\n",
      "Learning curves help understand how your learning algorithm is doing as a function of the amount of experience it has. Experience being the number of training examples it has.\n",
      "\n",
      "The bigger the training set the harder it is to fit all examples perfectly. Thus; as the training set increases so does the training error $J_{train}(\\vec{w},b)$ \n",
      "\n",
      "Plotting a learning curve by training different models based on different subsets of training data is computationally expensive, so in practice it isn't done that often. But, it's a good mental visualization.\n",
      "#### Slides\n",
      "!Screenshot 2023-10-17 at 5.40.04 PM.png\n",
      "\n",
      "\n",
      "\n",
      "### High Bias Example\n",
      "SECTION:  2 If a learning algorithm suffers from high bias, getting more training data will not (by itself) help that much.\n",
      "#### Slide for High Bias\n",
      "!Screenshot 2023-10-17 at 5.44.29 PM.png\n",
      "\n",
      "### High Variance Example\n",
      "If a learning algorithm suffers from high variance, getting more training data is likely to help.\n",
      "#### Slide for High Variance\n",
      "!Screenshot 2023-10-17 at 5.49.45 PM.png\n",
      "\n",
      "\n",
      "\n",
      "## Deciding what to try next revisited\n",
      "### Examples when Debugging an Algorithm:\n",
      "Get more training examples: fixes high variance\n",
      "Try smaller set of features: fixes high variance\n",
      "Try getting additional features: fixes high bias\n",
      "\tExamples; an algorithm that lacks information wont even do well on the training set\n",
      "Adding polynomial features ($x_1^2,X_2^2, etc$): Fixes high bias\n",
      "Decreasing $\\lambda$ Fixes high bias\n",
      "Increasing $\\lambda$ Fixes high variance\n",
      "\tForces the algorithm to force a smoother function.\n",
      "\n",
      "**Note!** Don't randomly throw away training examples just to fix a high bias problem.\n",
      "### Takeaway\n",
      "#merge with Bias and Variance ?\n",
      "If your algorithm has high variance, try simplifying your model or getting more training data. Simplification can mean a smaller set of features or an increased regularization\n",
      "If your algorithm has high bias, that is to say its not even doing well on the training set, you mainly need to make your model more powerful and flexible to fit more complex functions. To do so you can give it additional features, add polynomial features, or decrease $\\lambda$ \n",
      "\n",
      "## Bias/Variance and Neural Networks\n",
      "### The bias variance tradeoff\n",
      "Simple model = high bias\n",
      "Complex model = high variance\n",
      "Before neural networks, we had to worry about balancing this complexity between bias and variance. With neural networks we now are mostly worried about high variance. \n",
      "### Neural Networks and bias variance\n",
      "Large Neural Network|neural networks are low bias machines.\n",
      "If you make your neural network large enough you can almost always fit your training set well.\n",
      "#### Recipe for decreasing bias with a neural network\n",
      "1. Train a neural network\n",
      "2.  If the training set error $J_{train}(\\vec{w},b)$ is high relative to your baseline, increase the size of the neural network by adding hidden layers.\n",
      "3. Once $J_{train}(\\vec{w},b)$ is low enough, see if it does well on the cross validation set\n",
      "4.  If the cross validation set $J_{cv}(\\vec{w},b)$ is too high, add more data, then test again from step 2.\n",
      "5. Repeat until $J_{cv}(\\vec{w},b)$  is low enough for your liking.\n",
      "##### Slide Illustration\n",
      "!Screenshot 2023-10-17 at 6.38.46 PM.png\n",
      "### Limitations and Notes\n",
      "Bigger networks are restricted by your computing power, data is restricted to the amount of data you have.\n",
      "\n",
      "Sometimes you will pingpong back between high bias and high variance as you move through this recipe and develop a machine learning algorithm. Use these observations to shape what you do next in the process.\n",
      "\n",
      "### Neural Networks and Regularization\n",
      "A large neural network will usually do as well or better than a smaller one so long as regularization is chosen appropriately.\n",
      "Of course, larger neural networks are more computationally expensive.\n",
      "### Neural Network Regularization #important \n",
      "#function and TensorFlow implementation:\n",
      "!Screenshot 2023-10-17 at 6.46.28 PM.png*Note usually don't regularize B, it doesn't really affect anything*\n",
      "# Python Notes\n",
      "## Keywords\n",
      "From codecademy\n",
      "- Continue Keyword: used inside a loop to skip the remaining loop code block and begin the next loop iteration.\n",
      "- Break keyword escapes the loop, regardless of the iteration number. Once break executes the program will continue to execute after the loop.\n",
      "## New Techniques\n",
      "- List Comprehension\n",
      "\t- Run loops within a list:\n",
      "\t- `new_prices=[price - 5 for price in prices]`\n",
      "\n",
      "\n",
      "This is similar to choosing the degree of the polynomial using Training, Test, and Dev Sets\n",
      "\n",
      "SECTION:  3 #dailyNote \n",
      "\n",
      "spam for note testing\n",
      "\n",
      "more preamble\n",
      "\n",
      "# Afternoon To-Do\n",
      "#meta #todoList \n",
      "## Priority\n",
      "Completed: Complete Python module\n",
      "Completed: Complete Bias and Variance\n",
      "## Bonus/tomorrow:\n",
      "Completed: Note cleanup with Aliases (see Career and Study To - Do)\n",
      "To Do: Linear Algebra Note Migration\n",
      "Completed: Integrate with this daily note\n",
      "\t\tTo Do: Training, Test, and Dev Sets\n",
      "\t\tTo Do: regularization (#merge and integrate)\n",
      "\t\tTo Do: Cost and Loss\n",
      "Completed: Big overhaul of Bias and Variance with regards to todays notes. \n",
      "# Machine Learning Specialization Notes:\n",
      "These notes will be integrated into other notes but kept here in their entirety.\n",
      "## Bias and Variance\n",
      "Machine Learning Specialization Advanced Machine Learning Algorithms, Week 3\n",
      "\n",
      "Models almost never work the first time you try them out. Let's see how we can fix them.\n",
      "\n",
      "### Diagnosing Bias/Variance\n",
      "See Bias and Variance\n",
      "\n",
      "If you have more features, you can't visualize Bias and Variance\n",
      "\n",
      "A more systematic way to see if you have high bias or high variance is to look at the performance of the algorithm on the Training, Test, and Dev Sets|training set and dev set\n",
      "\n",
      "A characteristic of a High Bias (under-fit) model is that $Jtrain$ (cost of the Training, Test, and Dev Sets|training set) is high.\n",
      "A characteristic of a High Variance (overfit) model is that $J_{cv}$ is high but $J_{train}$ is low.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.26.00 PM.png\n",
      "\n",
      "### Understanding Bias and Variance\n",
      "Take degree of polynomial $d$\n",
      "As $d$ increases, that is to say we add degrees to the polynomial\n",
      "$J_{train}({\\vec{w},b})$  will decrease.\n",
      "$J_{cv}(\\vec{w},b)$ dips towards the middle, showing the ideal degree for the polynomial.\n",
      "\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.29.21 PM.png\n",
      "\n",
      "### Technique for Diagnosing Bias and Variance\n",
      "How do you tell if your algorithm has a high bias or variance problem?\n",
      "\n",
      "One key takeaway is that high bias means it is not even doing well on the training set and high variance means it does much worse on the cross validation set and the training set.\n",
      "#### High Bias (under-fit)\n",
      "In an under-fit model $J_{train}$ will be high and $J_{train} \\approx J_{cv}$ \n",
      "#### High Variance (overfit)\n",
      "In an over-fit model $J_{cv} \\gg J_{train}$ and $J_{train}$ will be low.\n",
      "#### High Bias and High Variance\n",
      "In a model with both high bias and high variance $J_{train}$ will be high and $J_{cv} \\gg J_{train}$ \n",
      "This is rare, and doesn't really happen for linear models with one $d$, but it does happen.\n",
      "This is when it overfits for some part of the input and under-fits for another part of the input.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 1.38.51 PM.png\n",
      "\n",
      "## Regularization and bias/variance\n",
      "### Linear Regression with Regularization\n",
      "Regularized Linear Regression model:\n",
      "Lambda $\\lambda$ is the regularization parameter\n",
      "(Big #merge and cleanup needed here in the regularization, Regularized Linear Regression, cost, Cost and Loss, loss, Loss Function, etc. Aliases are needed in many of these)\n",
      "\n",
      "Take this model: $$f_{\\vec{w},b}(x)=w_1+w_2x^2 + w_4x^4+b$$\n",
      "SECTION:  4 With this regularization|regularized Cost and Loss $$J(\\vec{w},b)=\\frac{1}{2m} \\sum_{i=1}^{m}(f_{\\vec{w},{b}}(\\vec{x}^{(i)}-y^{(i)})^2+\\frac{\\lambda}{2m} \\sum_{j=1}^nw_j^2$$\n",
      "\n",
      "If lambda is large, say $\\lambda = 10,000$ than $w_1 \\approx 0, W_2 \\approx 0$ and $f_{\\vec{x},b}\\vec{x} \\approx b$, thus the model creates a flat line.\n",
      "This is underfit, $J_{train}()\n",
      "\n",
      "On the other hand, if we set $\\lambda=0$, then we have a forth order polynomial with no regularization. We end up with a very overfit curve.\n",
      "\n",
      "So, how do we find a good value for $\\lambda$?\n",
      "##### Slide\n",
      "!Screenshot 2023-10-17 at 3.56.53 PM.png\n",
      "### Choosing the Regularization parameter $\\lambda$ \n",
      "\n",
      "This will be similar to choosing $d$ with cross validation\n",
      "Try multiple values for $\\lambda$ and then choose the option with the lowest cost.\n",
      "### Slide\n",
      "!Screenshot 2023-10-17 at 4.15.27 PM.png\n",
      "### Bias and Variance as a Function of regularization parameter $\\lambda$ \n",
      "Cross Validation tries out many versions of $\\lambda$ and then chooses the one with the lowest cost.\n",
      "Cross validation will help find us a a good value of $d$ as well as $\\lambda$ \n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 4.14.07 PM.png\n",
      "\n",
      "\n",
      "## Establishing A Baseline Level of Performance\n",
      "### Speech Recognition example\n",
      "Job is to take in audio and output the text of what a person is saying\n",
      "\n",
      "Training error $J_{train}$ is percentage of audio clips that the program does not transcribe correctly in it's entirety.\n",
      "Lets say:\n",
      "\tHuman Level Performance: 10.6\n",
      "\t$J_{train}$: 10.8%\n",
      "\t$J_{cv}$: 14.8%\n",
      "\n",
      "Why is human level error so high? There is lots of noise in the audio. It seems unfair to expect a learning algorithm to do much better.\n",
      "It is thus is more useful to measure the training error against the human error.\n",
      "So, looking at these results, $J_{train}$ is only 0.2$ higher than the human level performance whereas $J_{cv}$ is a full 4.2% higher.\n",
      "We can thus conclude that this algorithm has more of a variance problem than a bias problem.\n",
      "### Establishing a baseline level of performance\n",
      "What is the level of error you can reasonably hope to get to?\n",
      "- Human level performance\n",
      "- Competing algorithms performance\n",
      "- Guess based on experience\n",
      "### Bias Variance Examples\n",
      "Gap between baseline and training error shows high bias.\n",
      "A gap between training error and cross validation error shows high variance.\n",
      "\n",
      "If your goal is perfection, the baseline would be zero. But for a lot of real world examples, like audio recognition, there is a lot of noise in the data, so you need a higher baseline.\n",
      "\n",
      "If there is a gap between all three is high you have both high bias and high variance.\n",
      "#### Slide\n",
      "!Screenshot 2023-10-17 at 4.42.49 PM.png\n",
      "\n",
      "\n",
      "## Learning Curves\n",
      "\n",
      "Noted in Learning Curves\n",
      "### Overview\n",
      "Learning curves help understand how your learning algorithm is doing as a function of the amount of experience it has. Experience being the number of training examples it has.\n",
      "\n",
      "The bigger the training set the harder it is to fit all examples perfectly. Thus; as the training set increases so does the training error $J_{train}(\\vec{w},b)$ \n",
      "\n",
      "Plotting a learning curve by training different models based on different subsets of training data is computationally expensive, so in practice it isn't done that often. But, it's a good mental visualization.\n",
      "#### Slides\n",
      "!Screenshot 2023-10-17 at 5.40.04 PM.png\n",
      "\n",
      "\n",
      "\n",
      "### High Bias Example\n",
      "SECTION:  5 If a learning algorithm suffers from high bias, getting more training data will not (by itself) help that much.\n",
      "#### Slide for High Bias\n",
      "!Screenshot 2023-10-17 at 5.44.29 PM.png\n",
      "\n",
      "### High Variance Example\n",
      "If a learning algorithm suffers from high variance, getting more training data is likely to help.\n",
      "#### Slide for High Variance\n",
      "!Screenshot 2023-10-17 at 5.49.45 PM.png\n",
      "\n",
      "\n",
      "\n",
      "## Deciding what to try next revisited\n",
      "### Examples when Debugging an Algorithm:\n",
      "Get more training examples: fixes high variance\n",
      "Try smaller set of features: fixes high variance\n",
      "Try getting additional features: fixes high bias\n",
      "\tExamples; an algorithm that lacks information wont even do well on the training set\n",
      "Adding polynomial features ($x_1^2,X_2^2, etc$): Fixes high bias\n",
      "Decreasing $\\lambda$ Fixes high bias\n",
      "Increasing $\\lambda$ Fixes high variance\n",
      "\tForces the algorithm to force a smoother function.\n",
      "\n",
      "**Note!** Don't randomly throw away training examples just to fix a high bias problem.\n",
      "### Takeaway\n",
      "#merge with Bias and Variance ?\n",
      "If your algorithm has high variance, try simplifying your model or getting more training data. Simplification can mean a smaller set of features or an increased regularization\n",
      "If your algorithm has high bias, that is to say its not even doing well on the training set, you mainly need to make your model more powerful and flexible to fit more complex functions. To do so you can give it additional features, add polynomial features, or decrease $\\lambda$ \n",
      "\n",
      "## Bias/Variance and Neural Networks\n",
      "### The bias variance tradeoff\n",
      "Simple model = high bias\n",
      "Complex model = high variance\n",
      "Before neural networks, we had to worry about balancing this complexity between bias and variance. With neural networks we now are mostly worried about high variance. \n",
      "### Neural Networks and bias variance\n",
      "Large Neural Network|neural networks are low bias machines.\n",
      "If you make your neural network large enough you can almost always fit your training set well.\n",
      "#### Recipe for decreasing bias with a neural network\n",
      "1. Train a neural network\n",
      "2.  If the training set error $J_{train}(\\vec{w},b)$ is high relative to your baseline, increase the size of the neural network by adding hidden layers.\n",
      "3. Once $J_{train}(\\vec{w},b)$ is low enough, see if it does well on the cross validation set\n",
      "4.  If the cross validation set $J_{cv}(\\vec{w},b)$ is too high, add more data, then test again from step 2.\n",
      "5. Repeat until $J_{cv}(\\vec{w},b)$  is low enough for your liking.\n",
      "##### Slide Illustration\n",
      "!Screenshot 2023-10-17 at 6.38.46 PM.png\n",
      "### Limitations and Notes\n",
      "Bigger networks are restricted by your computing power, data is restricted to the amount of data you have.\n",
      "\n",
      "Sometimes you will pingpong back between high bias and high variance as you move through this recipe and develop a machine learning algorithm. Use these observations to shape what you do next in the process.\n",
      "\n",
      "### Neural Networks and Regularization\n",
      "A large neural network will usually do as well or better than a smaller one so long as regularization is chosen appropriately.\n",
      "Of course, larger neural networks are more computationally expensive.\n",
      "### Neural Network Regularization #important \n",
      "#function and TensorFlow implementation:\n",
      "!Screenshot 2023-10-17 at 6.46.28 PM.png*Note usually don't regularize B, it doesn't really affect anything*\n",
      "# Python Notes\n",
      "## Keywords\n",
      "From codecademy\n",
      "- Continue Keyword: used inside a loop to skip the remaining loop code block and begin the next loop iteration.\n",
      "- Break keyword escapes the loop, regardless of the iteration number. Once break executes the program will continue to execute after the loop.\n",
      "## New Techniques\n",
      "- List Comprehension\n",
      "\t- Run loops within a list:\n",
      "\t- `new_prices=[price - 5 for price in prices]`\n",
      "\n",
      "\n",
      "This is similar to choosing the degree of the polynomial using Training, Test, and Dev Sets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, section in enumerate(output_sections):\n",
    "    print(\"SECTION: \", i, \"\\n\", section.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "    print(type(note))\n",
    "    print(len(tokenizer(note)[0]))\n",
    "    #print(summarize_string(note, summarizer, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
